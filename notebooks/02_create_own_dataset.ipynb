{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94a68d6-8096-4877-94e9-9d4bf8a61ce7",
   "metadata": {},
   "source": [
    "# 2. PyTorch dataset and data loader\n",
    "\n",
    "In the previous notebook, we have learned how to investigate our dataset. Next up, we'll want to create a PyTorch `Dataset` and a PyTorch `DataLoader`. These will help us get our data ready to be passed through a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d37052-c196-40d7-8f64-3c4468943576",
   "metadata": {},
   "source": [
    "## 2.1 Creating a PyTorch dataset\n",
    "\n",
    "A [PyTorch `Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) is an abstract representation of a dataset. You can do two things with a PyTorch `Dataset`: get the *item* at a certain **index**, and get the **length** of the dataset (i.e., the number of *items*). That's all. What an *item* is, is entirely up to you, but in the case of classification, it is typically a tuple of an image and a class label.\n",
    "\n",
    "### 2.1.1 Built-in datasets\n",
    "\n",
    "Torchvision already includes [many datasets](https://pytorch.org/vision/stable/datasets.html) to play around with. Let's take a look at the [MNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ececd578-3ad8-4716-8f01-6f4a515cd45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 9912422/9912422 [00:00<00:00, 58442430.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 28881/28881 [00:00<00:00, 118206.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 1648877/1648877 [00:00<00:00, 36052188.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 4542/4542 [00:00<00:00, 31230375.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist_ds = MNIST('../data/', train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf2a345-1ce2-4cb8-8669-f6c7317e56a1",
   "metadata": {},
   "source": [
    "We can ask an item at a certain index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc48dd3-17f3-4bb1-a784-30cca2c2a361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28>, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2b470-09e4-4a6f-87ff-33d8b6936adc",
   "metadata": {},
   "source": [
    "This gives us two things: an image and an integer label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d60429-ab19-40ae-af49-caa278051341",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = mnist_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7214a64b-f77d-416c-8cf1-c3fa8f5bb7cd",
   "metadata": {},
   "source": [
    "We can also ask the length of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f051a95-db79-4728-8a2e-671a74b2eed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba72ca3c-2260-4e5c-9f48-e4d4c8b5e696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aed50edb-f69a-4fa4-b42c-134064d8f826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7000f987-7875-4291-9a73-4c726df244e8",
   "metadata": {},
   "source": [
    "### 2.1.2 A first attempt to a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8cdd9b-7d3d-4bc6-8dc9-35a0f9f56080",
   "metadata": {},
   "source": [
    "To implement your own dataset, you need create a class that inherits from [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and implements two methods: `__getitem__()` and `__len__()`.\n",
    "\n",
    "For our Pokémon use case:\n",
    "\n",
    "- `__getitem__()` should return the image at the given index, along with the name of that Pokémon;\n",
    "- `__len__()` should return the number of images.\n",
    "\n",
    "In the previous notebook, we saw how we can represent our dataset as a Pandas `DataFrame`. We can use this representation to implement `__getitem__()` and `__len__()` without much new code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d216f401-6c17-49ba-ba4c-39b995a4fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path \n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "\n",
    "data_path = Path('../data/PokemonGen1')\n",
    "\n",
    "# list comprehension way\n",
    "df = pd.DataFrame ([\n",
    "    {\n",
    "    'image' : p,\n",
    "    'label' : p.parent.name\n",
    "    }\n",
    "    for p in data_path.glob('data/*/*')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33844882-8dc5-492e-afdf-b269866cfe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    ../data/PokemonGen1/data/Cubone/5a87cbf8f94cdd...\n",
       "label                                               Cubone\n",
       "Name: 300, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[300] # is een rij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64473049-fe00-4d2f-bd9c-bdb1d284f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammalsDataset(Dataset):\n",
    "    def __init__(self, datapath, transforms=None):\n",
    "        data_path = Path(datapath)\n",
    "        self.df = pd.DataFrame ([\n",
    "            {\n",
    "            'image' : p,\n",
    "            'label' : p.parent.name\n",
    "            }\n",
    "            for p in data_path.glob('data/*/*')\n",
    "        ])\n",
    "        self.transforms = transforms\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['image']\n",
    "        label = row['label']\n",
    "        img = Image.open(img_path)\n",
    "        if (self.transforms is not None):\n",
    "            img = self.transforms(img)\n",
    "        return img, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a4255-0d7d-4639-aa12-683405adf26c",
   "metadata": {},
   "source": [
    "We can play around with this dataset, just like with the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d076d02-4f1a-4be0-8108-ff2f11a27a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256>, 'porcupine')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = MammalsDataset('../data/mammals')\n",
    "ds[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f8bba-88e7-4227-9871-611c88d3d4bc",
   "metadata": {},
   "source": [
    "While this is already a perfectly valid PyTorch `Dataset`, there are two issues:\n",
    "\n",
    "1. Our labels are strings;\n",
    "2. We don't make a distinction between train, validation and test data.\n",
    "\n",
    "> 🤔 **Why is it a problem that our labels are strings?**\n",
    ">\n",
    "> When training a network, we typically iterate over *batches* of data. These batches are represented as PyTorch tensors. And it is not possible (and not necessary, really) to create a tensor of strings.\n",
    "\n",
    "We'll solve both issues in the following sections.\n",
    "\n",
    "### 2.1.3 Replacing string labels with integer labels\n",
    "\n",
    "First, we'll replace our string labels by integer labels. For this, we'll create a dictionary that maps each string label to a unique integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc2e6dcd-2213-4819-85ff-0d2d33381d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/mammals')\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'image': str(img_path),\n",
    "        'label': img_path.parent.name\n",
    "    }\n",
    "    for img_path in data_path.glob('data/*/*')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28016453-d16e-421f-95dc-e683d16152db",
   "metadata": {},
   "source": [
    "To get a list of unique labels, we can call [`unique()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html) on the `label` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fde56d57-3c95-497f-b6c6-3af4bca7f993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0            porcupine\n",
       "1            porcupine\n",
       "2            porcupine\n",
       "3            porcupine\n",
       "4            porcupine\n",
       "             ...      \n",
       "13746    water_buffalo\n",
       "13747    water_buffalo\n",
       "13748    water_buffalo\n",
       "13749    water_buffalo\n",
       "13750    water_buffalo\n",
       "Name: label, Length: 13751, dtype: object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f8294b-8e4d-4524-b150-cc97692fa7c5",
   "metadata": {},
   "source": [
    "To ensure a consistent mapping across different systems, we can sort these labels with [the built-in Python function `sorted()`](https://docs.python.org/3/library/functions.html#sorted):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80660a93-a955-459c-9221-435b19542d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['african_elephant',\n",
       " 'alpaca',\n",
       " 'american_bison',\n",
       " 'anteater',\n",
       " 'arctic_fox',\n",
       " 'armadillo',\n",
       " 'baboon',\n",
       " 'badger',\n",
       " 'blue_whale',\n",
       " 'brown_bear',\n",
       " 'camel',\n",
       " 'dolphin',\n",
       " 'giraffe',\n",
       " 'groundhog',\n",
       " 'highland_cattle',\n",
       " 'horse',\n",
       " 'jackal',\n",
       " 'kangaroo',\n",
       " 'koala',\n",
       " 'manatee',\n",
       " 'mongoose',\n",
       " 'mountain_goat',\n",
       " 'opossum',\n",
       " 'orangutan',\n",
       " 'otter',\n",
       " 'polar_bear',\n",
       " 'porcupine',\n",
       " 'red_panda',\n",
       " 'rhinoceros',\n",
       " 'sea_lion',\n",
       " 'seal',\n",
       " 'snow_leopard',\n",
       " 'squirrel',\n",
       " 'sugar_glider',\n",
       " 'tapir',\n",
       " 'vampire_bat',\n",
       " 'vicuna',\n",
       " 'walrus',\n",
       " 'warthog',\n",
       " 'water_buffalo',\n",
       " 'weasel',\n",
       " 'wildebeest',\n",
       " 'wombat',\n",
       " 'yak',\n",
       " 'zebra']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3739f9-16da-41ef-8bc2-2ace902a8e34",
   "metadata": {},
   "source": [
    "Now, with [the built-in Python function `enumerate()`](https://docs.python.org/3/library/functions.html#enumerate), we can get an iterable that yields another integer value for each of our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "708d8878-6e36-49b2-8c8c-51fe01c0f3a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 african_elephant\n",
      "1 alpaca\n",
      "2 american_bison\n",
      "3 anteater\n",
      "4 arctic_fox\n",
      "5 armadillo\n",
      "6 baboon\n",
      "7 badger\n",
      "8 blue_whale\n",
      "9 brown_bear\n",
      "10 camel\n",
      "11 dolphin\n",
      "12 giraffe\n",
      "13 groundhog\n",
      "14 highland_cattle\n",
      "15 horse\n",
      "16 jackal\n",
      "17 kangaroo\n",
      "18 koala\n",
      "19 manatee\n",
      "20 mongoose\n",
      "21 mountain_goat\n",
      "22 opossum\n",
      "23 orangutan\n",
      "24 otter\n",
      "25 polar_bear\n",
      "26 porcupine\n",
      "27 red_panda\n",
      "28 rhinoceros\n",
      "29 sea_lion\n",
      "30 seal\n",
      "31 snow_leopard\n",
      "32 squirrel\n",
      "33 sugar_glider\n",
      "34 tapir\n",
      "35 vampire_bat\n",
      "36 vicuna\n",
      "37 walrus\n",
      "38 warthog\n",
      "39 water_buffalo\n",
      "40 weasel\n",
      "41 wildebeest\n",
      "42 wombat\n",
      "43 yak\n",
      "44 zebra\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(sorted(df['label'].unique())):\n",
    "    print(i, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb35df-3a02-49c0-817b-eede45a64a5f",
   "metadata": {},
   "source": [
    "So, we can create our label-to-integer dictionary with the following `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aba3371c-e5ca-4866-adbd-9e66eab8b7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'african_elephant': 0,\n",
       " 'alpaca': 1,\n",
       " 'american_bison': 2,\n",
       " 'anteater': 3,\n",
       " 'arctic_fox': 4,\n",
       " 'armadillo': 5,\n",
       " 'baboon': 6,\n",
       " 'badger': 7,\n",
       " 'blue_whale': 8,\n",
       " 'brown_bear': 9,\n",
       " 'camel': 10,\n",
       " 'dolphin': 11,\n",
       " 'giraffe': 12,\n",
       " 'groundhog': 13,\n",
       " 'highland_cattle': 14,\n",
       " 'horse': 15,\n",
       " 'jackal': 16,\n",
       " 'kangaroo': 17,\n",
       " 'koala': 18,\n",
       " 'manatee': 19,\n",
       " 'mongoose': 20,\n",
       " 'mountain_goat': 21,\n",
       " 'opossum': 22,\n",
       " 'orangutan': 23,\n",
       " 'otter': 24,\n",
       " 'polar_bear': 25,\n",
       " 'porcupine': 26,\n",
       " 'red_panda': 27,\n",
       " 'rhinoceros': 28,\n",
       " 'sea_lion': 29,\n",
       " 'seal': 30,\n",
       " 'snow_leopard': 31,\n",
       " 'squirrel': 32,\n",
       " 'sugar_glider': 33,\n",
       " 'tapir': 34,\n",
       " 'vampire_bat': 35,\n",
       " 'vicuna': 36,\n",
       " 'walrus': 37,\n",
       " 'warthog': 38,\n",
       " 'water_buffalo': 39,\n",
       " 'weasel': 40,\n",
       " 'wildebeest': 41,\n",
       " 'wombat': 42,\n",
       " 'yak': 43,\n",
       " 'zebra': 44}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_int = {}\n",
    "for i, label in enumerate(sorted(df['label'].unique())):\n",
    "    label_to_int[label] = i\n",
    "label_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27170a9-ee1e-4029-8d37-5e1f80b0e59e",
   "metadata": {},
   "source": [
    "Or, we can use a [dictionary comprehension](https://www.geeksforgeeks.org/python-dictionary-comprehension/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba271583-162f-4393-bd02-e4063a035d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'african_elephant': 0,\n",
       " 'alpaca': 1,\n",
       " 'american_bison': 2,\n",
       " 'anteater': 3,\n",
       " 'arctic_fox': 4,\n",
       " 'armadillo': 5,\n",
       " 'baboon': 6,\n",
       " 'badger': 7,\n",
       " 'blue_whale': 8,\n",
       " 'brown_bear': 9,\n",
       " 'camel': 10,\n",
       " 'dolphin': 11,\n",
       " 'giraffe': 12,\n",
       " 'groundhog': 13,\n",
       " 'highland_cattle': 14,\n",
       " 'horse': 15,\n",
       " 'jackal': 16,\n",
       " 'kangaroo': 17,\n",
       " 'koala': 18,\n",
       " 'manatee': 19,\n",
       " 'mongoose': 20,\n",
       " 'mountain_goat': 21,\n",
       " 'opossum': 22,\n",
       " 'orangutan': 23,\n",
       " 'otter': 24,\n",
       " 'polar_bear': 25,\n",
       " 'porcupine': 26,\n",
       " 'red_panda': 27,\n",
       " 'rhinoceros': 28,\n",
       " 'sea_lion': 29,\n",
       " 'seal': 30,\n",
       " 'snow_leopard': 31,\n",
       " 'squirrel': 32,\n",
       " 'sugar_glider': 33,\n",
       " 'tapir': 34,\n",
       " 'vampire_bat': 35,\n",
       " 'vicuna': 36,\n",
       " 'walrus': 37,\n",
       " 'warthog': 38,\n",
       " 'water_buffalo': 39,\n",
       " 'weasel': 40,\n",
       " 'wildebeest': 41,\n",
       " 'wombat': 42,\n",
       " 'yak': 43,\n",
       " 'zebra': 44}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_int = {label : i for i, label in enumerate(sorted(df['label'].unique()))}\n",
    "label_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb7c89-fd4a-438b-b95b-d529aa54adbf",
   "metadata": {},
   "source": [
    "We can plug this into our mamalDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "704c42e3-c94d-4423-80d7-67fe3a7532a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammalsDataset(Dataset):\n",
    "    def __init__(self, datapath, transforms=None):\n",
    "        data_path = Path(datapath)\n",
    "        df = pd.DataFrame ([\n",
    "            {\n",
    "            'image' : p,\n",
    "            'label' : p.parent.name\n",
    "            }\n",
    "            for p in data_path.glob('data/*/*')\n",
    "        ])\n",
    "\n",
    "        # mappen van label naar integer\n",
    "        label_to_int = {label : i for i, label in enumerate(sorted(df['label'].unique()))}\n",
    "        \n",
    "        # store attributes\n",
    "        self.data_path = data_path\n",
    "        self.label_to_int = label_to_int\n",
    "        self.transforms = transforms\n",
    "        self.df = df\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['image']\n",
    "        label = row['label']\n",
    "        int_label = self.label_to_int[label]\n",
    "        img = Image.open(img_path)\n",
    "        if (self.transforms is not None):\n",
    "            img = self.transforms(img)\n",
    "        return (img, label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9383a4-23a8-497a-aba6-9814b3e07ca7",
   "metadata": {},
   "source": [
    "Let's try out our new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80867fbd-c0eb-42f1-b076-2fcc5e6cee9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MammalsDataset.__init__() missing 1 required positional argument: 'subset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mMammalsDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/mammals/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ds[\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: MammalsDataset.__init__() missing 1 required positional argument: 'subset'"
     ]
    }
   ],
   "source": [
    "ds = MammalsDataset('../data/mammals/')\n",
    "ds[10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98bad5cc-d9b1-4654-8a0d-e28d8c1d40e0",
   "metadata": {},
   "source": [
    "### 2.1.4 Splitting the data into a train, validation and test split\n",
    "\n",
    "Training a neural network and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would achieve a perfect score but would fail to predict anything useful on data that was not used during training. This situation is called **overfitting**. To get a better sense of model performance on *unseen* data, it is customary to randomly split the dataset into three disjoint subsets.\n",
    "\n",
    "1. **Training set**: You train the model with the training set.\n",
    "2. **Validation set**: Every X training iterations, you evaluate the model performance on the validation set. It is common to only keep the model that obtained the best validation score during training. When training multiple models with different configurations (or *hyperparameters*), you should use the evaluation on the validation set to decide which model to keep.\n",
    "3. **Test set**: *Once you have decided a model based on validation perfomance*, you evaluate on the test set to get an estimate of the model's ability to generalize to unseen data. In many machine learning competitions, to avoid cheating, the test set is either unlabeled or unavailable to the participants.\n",
    "\n",
    "As you see, the validation set is used to compare different model configurations, or *hyperparameters*. This could simply be the number of iterations used to train the model, but this also includes the choice of data augmentations, optimizer, learning rate, model architecture (number of layers, number of neurons in a layer, kind of layer,...) etc.\n",
    "\n",
    "To split our dataset into these subsets, we can use [`sklearn.model_selection.train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68764b71-5999-4d8a-b083-f37cb7c485b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b585a23-98f5-48ab-988c-e37741604430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainval, df_test = train_test_split(df, train_size=0.8, random_state=42)\n",
    "df_train, df_val = train_test_split(df_trainval, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65161a8-5a34-4060-9b25-d137db5e7f65",
   "metadata": {},
   "source": [
    "We can update our `mammals` so that, depending on a given constructor argument, the correct subset is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "023a3f16-f244-46a8-a0cf-b6e433eb4adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammalsDataset(Dataset):\n",
    "    def __init__(self, datapath, subset, transforms=None):\n",
    "        data_path = Path(datapath)\n",
    "        df = pd.DataFrame ([\n",
    "            {\n",
    "            'image' : p,\n",
    "            'label' : p.parent.name\n",
    "            }\n",
    "            for p in data_path.glob('data/*/*')\n",
    "        ])\n",
    "\n",
    "        # mappen van label naar integer\n",
    "        label_to_int = {label : i for i, label in enumerate(sorted(df['label'].unique()))}\n",
    "\n",
    "        # subsets data\n",
    "        df_trainval, df_test = train_test_split(df, train_size=0.8, random_state=42)\n",
    "        df_train, df_val = train_test_split(df_trainval, train_size=0.8, random_state=42)\n",
    "            \n",
    "        # store attributes\n",
    "        self.data_path = data_path\n",
    "        self.label_to_int = label_to_int\n",
    "        self.transforms = transforms\n",
    "        self.df = df\n",
    "        self.subset = subset\n",
    "\n",
    "        if subset == 'train':\n",
    "            self.df = df_train.reset_index()\n",
    "        elif subset == 'val':\n",
    "            self.df = df_val.reset_index()\n",
    "        elif subset == 'test':\n",
    "            self.df = df_test.reset_index()\n",
    "        else:\n",
    "            raise ValueError(f'Unknown subset {subset}')\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['image']\n",
    "        label = row['label']\n",
    "        int_label = self.label_to_int[label]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if (self.transforms is not None):\n",
    "            img = self.transforms(img)\n",
    "        return (img, label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c44e40-ed2e-44d5-9cd0-59d363450952",
   "metadata": {},
   "source": [
    "Let's try it out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89fc150f-ffe1-41ab-967c-d1e583eaea81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MammalsDataset at 0x7f59541409a0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = MammalsDataset(datapath='../data/mammals', subset='train')\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138eebc-b542-40eb-9487-86c59d557496",
   "metadata": {},
   "source": [
    "### 2.1.5 Cross-validation\n",
    "\n",
    "Choosing the model that achieved the best performance on the validation set (instead of the training set) avoids selecting a model that has overfit. However, when comparing many models based on validation score, we might select a model that only worked best for the particular random choice of training and validation data. To make a better-informed decision, we can use **cross-validation** techniques.\n",
    "\n",
    "A basic cross-validation technique is **$k$-fold cross-validation**. Here, the data set is first split up into only two subsets: a *training* set and a *test* set. The training set is partitioned into **$k$ equally-sized folds**. When training a model, we choose one fold for *validation* and the other $k - 1$ folds for *training*. By training a certain model configuration with all $k$ different choices for training and validation and averaging the validation scores, we can effectively select the best model configuration in a more reliable and robust manner. The figure below illustrates the process of $k$-fold cross-validation ([source](https://scikit-learn.org/stable/modules/cross_validation.html)).\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" style=\"max-width: 500px; margin: auto; padding: 2em;\"/>\n",
    "\n",
    "To add support for $k$-fold cross validation to our `mammals`, we'll first use `train_test_split()` to split our dataset into train+val and test set. Then, with [`numpy.array_split()`](https://numpy.org/doc/stable/reference/generated/numpy.array_split.html), we can split the train+val set into $k$ folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e7c5f90-ddbb-402e-97e8-c4bd7110b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b39eb156-a676-48df-87b3-95e0a8ae7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geef aantal k-fold\n",
    "k = 5\n",
    "\n",
    "# split de dataset in train + validatie\n",
    "df_trainval, df_test = train_test_split(df, train_size=0.8, random_state=42)\n",
    "\n",
    "# split de training + validatie in k fold\n",
    "folds = np.array_split(df_trainval, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8307f642-050e-41e9-bbd6-3e142b537e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>../data/mammals/data/american_bison/american_b...</td>\n",
       "      <td>american_bison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>../data/mammals/data/sugar_glider/sugar_glider...</td>\n",
       "      <td>sugar_glider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>../data/mammals/data/tapir/tapir-0282.jpg</td>\n",
       "      <td>tapir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>../data/mammals/data/tapir/tapir-0130.jpg</td>\n",
       "      <td>tapir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9056</th>\n",
       "      <td>../data/mammals/data/wildebeest/wildebeest-025...</td>\n",
       "      <td>wildebeest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>../data/mammals/data/sea_lion/sea_lion-0265.jpg</td>\n",
       "      <td>sea_lion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>../data/mammals/data/snow_leopard/snow_leopard...</td>\n",
       "      <td>snow_leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>../data/mammals/data/opossum/opossum-0290.jpg</td>\n",
       "      <td>opossum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12060</th>\n",
       "      <td>../data/mammals/data/brown_bear/brown_bear-019...</td>\n",
       "      <td>brown_bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12560</th>\n",
       "      <td>../data/mammals/data/groundhog/groundhog-0289.jpg</td>\n",
       "      <td>groundhog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image           label\n",
       "5263   ../data/mammals/data/american_bison/american_b...  american_bison\n",
       "4344   ../data/mammals/data/sugar_glider/sugar_glider...    sugar_glider\n",
       "3526           ../data/mammals/data/tapir/tapir-0282.jpg           tapir\n",
       "3519           ../data/mammals/data/tapir/tapir-0130.jpg           tapir\n",
       "9056   ../data/mammals/data/wildebeest/wildebeest-025...      wildebeest\n",
       "...                                                  ...             ...\n",
       "4718     ../data/mammals/data/sea_lion/sea_lion-0265.jpg        sea_lion\n",
       "1888   ../data/mammals/data/snow_leopard/snow_leopard...    snow_leopard\n",
       "711        ../data/mammals/data/opossum/opossum-0290.jpg         opossum\n",
       "12060  ../data/mammals/data/brown_bear/brown_bear-019...      brown_bear\n",
       "12560  ../data/mammals/data/groundhog/groundhog-0289.jpg       groundhog\n",
       "\n",
       "[2200 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb64f9-be7e-4001-930a-3317a6e35658",
   "metadata": {},
   "source": [
    "Now, we can choose which fold to use for validation. The other folds should be concatenated to create the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44ca9e13-2141-415e-a8dc-01887dd24785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   image             label\n",
      "6864   ../data/mammals/data/vampire_bat/vampire_bat-0...       vampire_bat\n",
      "489    ../data/mammals/data/rhinoceros/rhinoceros-011...        rhinoceros\n",
      "8685   ../data/mammals/data/highland_cattle/highland_...   highland_cattle\n",
      "690        ../data/mammals/data/opossum/opossum-0059.jpg           opossum\n",
      "602        ../data/mammals/data/opossum/opossum-0252.jpg           opossum\n",
      "...                                                  ...               ...\n",
      "13709  ../data/mammals/data/water_buffalo/water_buffa...     water_buffalo\n",
      "6052   ../data/mammals/data/african_elephant/african_...  african_elephant\n",
      "3178         ../data/mammals/data/vicuna/vicuna-0092.jpg            vicuna\n",
      "3192         ../data/mammals/data/vicuna/vicuna-0102.jpg            vicuna\n",
      "9499           ../data/mammals/data/otter/otter-0048.jpg             otter\n",
      "\n",
      "[2200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "fold_val = 3 # val fold kiezen \n",
    "df_val = fold[fold_val] # de array met validatie set\n",
    "\n",
    "train_folds = []\n",
    "\n",
    "for idx, df_fold in enumerate(folds):\n",
    "    if idx == fold_val:\n",
    "        continue\n",
    "    else:\n",
    "        train_folds.append(df_fold)\n",
    "\n",
    "print(df_train)\n",
    "df_train = pd.concat(train_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb21c21e-ec62-4d78-9870-657b83fa0109",
   "metadata": {},
   "source": [
    "Plugging this into our `mammals`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2f3d928-ed42-452a-b02a-827ddb9445fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammalsDataset(Dataset):\n",
    "    def __init__(self, datapath, subset, k=5, val_fold=0, transforms=None):\n",
    "        data_path = Path(datapath)\n",
    "        df = pd.DataFrame ([\n",
    "            {\n",
    "            'image' : p,\n",
    "            'label' : p.parent.name\n",
    "            }\n",
    "            for p in data_path.glob('data/*/*')\n",
    "        ])\n",
    "\n",
    "        # mappen van label naar integer\n",
    "        label_to_int = {label : i for i, label in enumerate(sorted(df['label'].unique()))}\n",
    "\n",
    "        # subsets of data\n",
    "        df_trainval, df_test = train_test_split(df, train_size=0.8, random_state=42)\n",
    "        df_train, df_val = train_test_split(df_trainval, train_size=0.8, random_state=42)\n",
    "\n",
    "         # Split into train, test, val\n",
    "        df_trainval, df_test = train_test_split(df, train_size=0.8, random_state=42)\n",
    "        folds = np.array_split(df_trainval, k)\n",
    "        df_val = folds[val_fold]\n",
    "        train_folds = [fold for i, fold in enumerate(folds)\n",
    "                       if i != val_fold]\n",
    "        df_train = pd.concat(train_folds)\n",
    "        \n",
    "        # store attributes\n",
    "        self.data_path = data_path\n",
    "        self.label_to_int = label_to_int\n",
    "        self.transforms = transforms\n",
    "\n",
    "        if subset == 'train':\n",
    "            self.df = df_train.reset_index()\n",
    "        elif subset == 'val':\n",
    "            self.df = df_val.reset_index()\n",
    "        elif subset == 'test':\n",
    "            self.df = df_test.reset_index()\n",
    "        else:\n",
    "            raise ValueError(f'Unknown subset {subset}')\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['image']\n",
    "        label = row['label']\n",
    "        int_label = self.label_to_int[label]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if (self.transforms is not None):\n",
    "            img = self.transforms(img)\n",
    "        return (img, label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb27d3b-93a7-45ad-a651-25c9d21b13b6",
   "metadata": {},
   "source": [
    "Now we can create a training set, validation set and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "333df9a0-1b73-4ece-a620-5c252714fe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/labo_bld_interp/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/home/student/labo_bld_interp/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/home/student/labo_bld_interp/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Create transforms\n",
    "train_tfms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomRotation(30),\n",
    "    v2.RandomResizedCrop(224, antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# mag geen random zijn bij validation pipeline (altijd zelfde input)\n",
    "val_tfms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize(224, antialias=True),\n",
    "    v2.CenterCrop(224),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "ds_train = MammalsDataset('../data/mammals', 'train', transforms=train_tfms)\n",
    "ds_val = MammalsDataset('../data/mammals', 'val', transforms=val_tfms)\n",
    "ds_test = MammalsDataset('../data/mammals', 'test', transforms=val_tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb8f52-a3ae-4ad0-aeda-31906cc7502a",
   "metadata": {},
   "source": [
    "> ⚠️ **Don't use random transforms for validation or test set!**\n",
    ">\n",
    "> To avoid making the validation and test evaluations irreproducible, you should not use randomness in the transforms that you'll use for the validation and test set.\n",
    "\n",
    "Hooray! 🙌 We now have a full-fledged PyTorch `Dataset` with support for $k$-fold cross-validation! 🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354dc290-0d9a-4d1d-b427-926424a92131",
   "metadata": {},
   "source": [
    "## 2.2 PyTorch data loader\n",
    "\n",
    "A PyTorch `Dataset` allows us to easily get images (and labels) from our dataset. When training a neural network, however, we can save training time by training with **batches** of data, instead of passing the images through the network one-by-one.\n",
    "\n",
    "Batching your data is the task of the [PyTorch `DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). Given a PyTorch `Dataset` that returns a tuple with an image tensor and an integer label, it is very simple to create a `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33459067-70bd-45e0-a3a5-c393ae9f0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create trainin data loader\n",
    "dl_train = DataLoader(ds_train, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c43cee-01c4-4c0a-89c3-0ad923165ed6",
   "metadata": {},
   "source": [
    "A `DataLoader` is an iterable, where each iteration item is a batch of data samples. As with any iterable in Python, you can iterate over a `DataLoader` using a `for` loop. Let's inspect what's inside an iteration item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a45a4fd8-8a2d-47ad-bed7-a83742ec1633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-0.5596, -0.5596, -0.5596,  ..., -0.6623, -0.6623, -0.6623],\n",
       "           [-0.5596, -0.5596, -0.5596,  ..., -0.6452, -0.6623, -0.6452],\n",
       "           [-0.5596, -0.5596, -0.5596,  ..., -0.6452, -0.6452, -0.6452],\n",
       "           ...,\n",
       "           [ 0.9988,  1.0502,  1.0844,  ...,  0.7933,  0.9132,  1.1358],\n",
       "           [ 1.2043,  1.0502,  0.8789,  ...,  1.0673,  0.8104,  0.7591],\n",
       "           [ 1.2728,  1.2043,  1.1187,  ...,  1.0159,  1.0159,  1.2214]],\n",
       " \n",
       "          [[ 0.5028,  0.5028,  0.5028,  ...,  0.4503,  0.4503,  0.4503],\n",
       "           [ 0.5028,  0.5028,  0.5028,  ...,  0.4678,  0.4503,  0.4678],\n",
       "           [ 0.5028,  0.5028,  0.5028,  ...,  0.4678,  0.4678,  0.4678],\n",
       "           ...,\n",
       "           [ 0.9405,  0.9930,  1.0280,  ...,  0.7129,  0.8354,  1.0630],\n",
       "           [ 1.1506,  0.9930,  0.8179,  ...,  0.9930,  0.7304,  0.6779],\n",
       "           [ 1.2206,  1.1506,  1.0630,  ...,  0.9580,  0.9580,  1.1681]],\n",
       " \n",
       "          [[ 2.0125,  2.0125,  2.0125,  ...,  1.8731,  1.8731,  1.8731],\n",
       "           [ 1.9777,  1.9777,  1.9777,  ...,  1.8905,  1.8731,  1.8905],\n",
       "           [ 1.9777,  1.9777,  1.9777,  ...,  1.8905,  1.8905,  1.8557],\n",
       "           ...,\n",
       "           [ 0.8797,  0.9319,  0.9842,  ...,  0.6531,  0.7751,  1.0017],\n",
       "           [ 1.0888,  0.9319,  0.7751,  ...,  0.9319,  0.6705,  0.6182],\n",
       "           [ 1.1585,  1.0888,  1.0017,  ...,  0.8971,  0.8971,  1.1062]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7352,  1.7009,  1.7009,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [ 1.5810,  1.6667,  1.7865,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [ 1.5639,  1.7180,  1.8550,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           ...,\n",
       "           [-2.1179, -2.1179, -2.1179,  ...,  0.3481,  0.3652,  0.3309],\n",
       "           [-2.1179, -2.1179, -2.1179,  ...,  0.3481,  0.2796,  0.2624],\n",
       "           [-2.1179, -2.1179, -2.1179,  ...,  0.3823,  0.3138,  0.2967]],\n",
       " \n",
       "          [[ 1.6583,  1.6232,  1.6057,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [ 1.5007,  1.5882,  1.6933,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [ 1.4832,  1.6232,  1.7633,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           ...,\n",
       "           [-2.0357, -2.0357, -2.0357,  ...,  1.0805,  1.0980,  1.1155],\n",
       "           [-2.0357, -2.0357, -2.0357,  ...,  1.0805,  1.0455,  1.0805],\n",
       "           [-2.0357, -2.0357, -2.0357,  ...,  1.1681,  1.1155,  1.1155]],\n",
       " \n",
       "          [[ 1.1934,  1.1411,  1.1062,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [ 1.0539,  1.1062,  1.2108,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [ 1.0365,  1.1585,  1.2805,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           ...,\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -0.2532, -0.2358, -0.2010],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -0.2184, -0.2881, -0.2532],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -0.1312, -0.2010, -0.2184]]],\n",
       " \n",
       " \n",
       "         [[[-0.1314, -0.0972, -0.0458,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-0.0972, -0.0629, -0.0287,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-0.0801, -0.0458, -0.0116,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           ...,\n",
       "           [-0.6109, -0.5767, -0.5596,  ..., -1.2788, -1.3130, -1.3987],\n",
       "           [-0.4054, -0.4397, -0.4226,  ..., -1.0219, -1.0219, -1.1418],\n",
       "           [-0.0458, -0.2342, -0.3369,  ..., -0.7993, -0.7993, -0.8849]],\n",
       " \n",
       "          [[ 0.2752,  0.3277,  0.3803,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [ 0.3102,  0.3452,  0.3978,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [ 0.3452,  0.3627,  0.4153,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           ...,\n",
       "           [-0.3200, -0.2500, -0.1975,  ..., -0.7927, -0.8452, -0.9503],\n",
       "           [-0.2150, -0.1975, -0.1275,  ..., -0.5651, -0.5826, -0.7227],\n",
       "           [ 0.0476, -0.0749, -0.1099,  ..., -0.3550, -0.3901, -0.4776]],\n",
       " \n",
       "          [[-0.3230, -0.2532, -0.1661,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-0.3055, -0.2532, -0.1661,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-0.3055, -0.2707, -0.2010,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           ...,\n",
       "           [ 0.4614,  0.5659,  0.6705,  ..., -0.1661, -0.2532, -0.3578],\n",
       "           [ 0.4614,  0.5659,  0.6879,  ...,  0.0431, -0.0092, -0.1487],\n",
       "           [ 0.6356,  0.5834,  0.6356,  ...,  0.2348,  0.1825,  0.0605]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.8961,  0.9132,  1.0673,  ...,  1.9749,  2.0434,  2.0434],\n",
       "           [ 0.9474,  0.9474,  1.0844,  ...,  1.9407,  2.0263,  2.0263],\n",
       "           [ 1.0673,  1.0844,  1.1358,  ...,  1.8550,  1.9578,  1.9578],\n",
       "           ...,\n",
       "           [-0.7993, -0.7993, -0.8164,  ..., -0.4911, -0.4739, -0.4739],\n",
       "           [-0.7822, -0.7822, -0.7993,  ..., -0.4911, -0.4568, -0.4568],\n",
       "           [-0.7822, -0.7822, -0.7993,  ..., -0.4911, -0.4568, -0.4568]],\n",
       " \n",
       "          [[-0.0924, -0.0749,  0.0826,  ...,  0.2927,  0.3277,  0.3277],\n",
       "           [-0.0399, -0.0224,  0.1001,  ...,  0.2577,  0.3102,  0.3102],\n",
       "           [ 0.1001,  0.1176,  0.1702,  ...,  0.1702,  0.2402,  0.2402],\n",
       "           ...,\n",
       "           [-1.3529, -1.3529, -1.3529,  ..., -0.8277, -0.8102, -0.8102],\n",
       "           [-1.3354, -1.3354, -1.3179,  ..., -0.8277, -0.7927, -0.7927],\n",
       "           [-1.3179, -1.3179, -1.3179,  ..., -0.8277, -0.7927, -0.7927]],\n",
       " \n",
       "          [[-0.9853, -0.9678, -0.7936,  ..., -0.5844, -0.5670, -0.5670],\n",
       "           [-0.9156, -0.8981, -0.7587,  ..., -0.6193, -0.5844, -0.5844],\n",
       "           [-0.6890, -0.6715, -0.6367,  ..., -0.7238, -0.6715, -0.6541],\n",
       "           ...,\n",
       "           [-1.4210, -1.4210, -1.4036,  ..., -1.0027, -0.9853, -0.9853],\n",
       "           [-1.3861, -1.3861, -1.3687,  ..., -0.9853, -0.9678, -0.9678],\n",
       "           [-1.3687, -1.3687, -1.3687,  ..., -0.9853, -0.9678, -0.9678]]],\n",
       " \n",
       " \n",
       "         [[[-1.7412, -1.7069, -1.7069,  ..., -1.7925, -1.8268, -1.8782],\n",
       "           [-1.6727, -1.6727, -1.6898,  ..., -1.7583, -1.7754, -1.7583],\n",
       "           [-1.6384, -1.6555, -1.6727,  ..., -1.7754, -1.7925, -1.7925],\n",
       "           ...,\n",
       "           [-0.2342, -0.2171, -0.1657,  ...,  0.6563,  0.7077,  0.6734],\n",
       "           [-0.3198, -0.1999,  0.0398,  ...,  0.7248,  0.7077,  0.5536],\n",
       "           [-0.7137, -0.6281, -0.3883,  ...,  0.9132,  1.1529,  0.9817]],\n",
       " \n",
       "          [[-1.7031, -1.6681, -1.6681,  ..., -1.7731, -1.8081, -1.8606],\n",
       "           [-1.6331, -1.6331, -1.6506,  ..., -1.7556, -1.7731, -1.7556],\n",
       "           [-1.5980, -1.6155, -1.6331,  ..., -1.7731, -1.7906, -1.7906],\n",
       "           ...,\n",
       "           [ 0.3277,  0.3102,  0.3277,  ...,  0.6779,  0.6954,  0.6604],\n",
       "           [ 0.2402,  0.3277,  0.5203,  ...,  0.7654,  0.7304,  0.5378],\n",
       "           [-0.1800, -0.1099,  0.0826,  ...,  0.9580,  1.2031,  1.0280]],\n",
       " \n",
       "          [[-1.5604, -1.5256, -1.5256,  ..., -1.5953, -1.6302, -1.6824],\n",
       "           [-1.4907, -1.4907, -1.5081,  ..., -1.5779, -1.5953, -1.5779],\n",
       "           [-1.4907, -1.5081, -1.5256,  ..., -1.5953, -1.6127, -1.6127],\n",
       "           ...,\n",
       "           [-0.4101, -0.4101, -0.3230,  ...,  0.8971,  0.9319,  0.8971],\n",
       "           [-0.4973, -0.3927, -0.1312,  ...,  0.9842,  0.9494,  0.7751],\n",
       "           [-0.8633, -0.7936, -0.5147,  ...,  1.1759,  1.4200,  1.2457]]],\n",
       " \n",
       " \n",
       "         [[[-0.6965, -0.7137, -0.6281,  ...,  1.3413,  1.2214,  1.1187],\n",
       "           [-0.0116,  0.1768,  0.3823,  ...,  1.4440,  1.3584,  1.3242],\n",
       "           [ 0.5707,  0.7933,  0.8276,  ...,  1.5468,  1.4954,  1.4783],\n",
       "           ...,\n",
       "           [-1.2103, -1.1760, -1.1932,  ..., -1.7925, -1.9295, -2.1179],\n",
       "           [-1.1075, -1.0562, -1.1760,  ..., -1.8782, -1.9980, -2.1008],\n",
       "           [-1.3302, -1.1760, -1.2103,  ..., -2.0152, -2.0665, -1.9980]],\n",
       " \n",
       "          [[-0.6176, -0.6001, -0.4951,  ...,  1.5007,  1.3782,  1.2731],\n",
       "           [ 0.0651,  0.2577,  0.4678,  ...,  1.6057,  1.5182,  1.4832],\n",
       "           [ 0.6254,  0.8704,  0.9055,  ...,  1.7108,  1.6583,  1.6408],\n",
       "           ...,\n",
       "           [-1.4405, -1.4055, -1.4055,  ..., -1.7556, -1.8606, -2.0357],\n",
       "           [-1.3179, -1.2829, -1.3880,  ..., -1.8431, -1.9307, -2.0182],\n",
       "           [-1.5455, -1.3880, -1.3880,  ..., -1.9657, -2.0007, -1.9132]],\n",
       " \n",
       "          [[-0.6193, -0.6193, -0.4973,  ...,  1.7163,  1.5942,  1.4897],\n",
       "           [ 0.1128,  0.3045,  0.5311,  ...,  1.8208,  1.7337,  1.6988],\n",
       "           [ 0.7576,  0.9842,  1.0191,  ...,  1.9254,  1.8731,  1.8557],\n",
       "           ...,\n",
       "           [-1.3164, -1.2816, -1.2816,  ..., -1.5430, -1.6476, -1.8044],\n",
       "           [-1.1944, -1.1421, -1.2641,  ..., -1.6302, -1.7173, -1.7870],\n",
       "           [-1.3861, -1.2293, -1.2467,  ..., -1.7522, -1.7696, -1.6824]]]]),\n",
       " ('seal',\n",
       "  'highland_cattle',\n",
       "  'brown_bear',\n",
       "  'sea_lion',\n",
       "  'vicuna',\n",
       "  'vicuna',\n",
       "  'arctic_fox',\n",
       "  'kangaroo',\n",
       "  'mountain_goat',\n",
       "  'brown_bear')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in dl_train:\n",
    "    break\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6e06e-ffb3-4b12-b79b-16137453115a",
   "metadata": {},
   "source": [
    "Our `DataLoader` composes the first batch with the samples at index $0,\\ldots, 9$, the second batch $10,\\ldots,19$ and so on. To compose the batches with random samples, you can pass `shuffle=True` to the `DataLoader` constructor.\n",
    "\n",
    "> ⚠️ **Only shuffle the training set!**\n",
    ">\n",
    "> It is considered bad practice to shuffle any of your evaluation sets, as this might make your evaluations irreproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4c7cc79-1ce6-4315-a2a0-871668fc42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa6e4c6-3cdc-4be5-a883-2eefb76219e0",
   "metadata": {},
   "source": [
    "When taking a look at the implementation of `__getitem__()` in our `PokemonDataset`, you'll see that it involves loading an image from disk with `read_image()` and applying image transforms. Both of these steps may block the computing process for a while. If we'd sequentially run `__getitem__()` for the 10 indices in our batch, it might take some time before the batch is created. Setting the argument `num_workers` as a positive integer will turn on **multi-process data loading** with the specified number of loader worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "737e4fb7-9e7e-4f43-833b-65847eb79eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=10, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0f976-19db-42ee-8f35-07cdc1d7e781",
   "metadata": {},
   "source": [
    "In summary, the following code creates our train, validation and test datasets and data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "463f2957-4ac5-4209-9dc1-594fde0d4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "dl_train = DataLoader(ds_train, batch_size=10, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=10, shuffle=False)\n",
    "dl_test = DataLoader(ds_test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0e5a5-b2fc-4c0a-9ed0-6a0e171bdf1c",
   "metadata": {},
   "source": [
    "And with this, we have covered everything on the data side! 💪 Our data is now ready to be passed into a neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4cccdf-820d-4540-abba-5ea4d3bf1381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
